{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc6428b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from clickhouse_connect import get_client\n",
    "from datetime import datetime, timedelta, date\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c865892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Получаем данные для проекта: Ozon-A&D Rus-1112223\n",
      "Данные получены для Ozon-A&D Rus-1112223\n",
      "Получаем данные для проекта: Ozon-Braun Russia-19885\n",
      "Данные получены для Ozon-Braun Russia-19885\n",
      "Получаем данные для проекта: Ozon-CASO-100304\n",
      "Данные получены для Ozon-CASO-100304\n",
      "Получаем данные для проекта: Ozon-Gillette-Club-80466\n",
      "Данные получены для Ozon-Gillette-Club-80466\n",
      "Получаем данные для проекта: Ozon-GUTENTECH-1547\n",
      "Данные получены для Ozon-GUTENTECH-1547\n",
      "Получаем данные для проекта: Ozon-KitchenAid-1638\n",
      "Данные получены для Ozon-KitchenAid-1638\n",
      "Получаем данные для проекта: Ozon-Smart Market-1676213\n",
      "Данные получены для Ozon-Smart Market-1676213\n"
     ]
    }
   ],
   "source": [
    "# === Список проектов с соответствующими переменными среды ===\n",
    "projects = [\n",
    "    {\n",
    "        \"name\": \"Ozon-A&D Rus-1112223\",\n",
    "        \"client_id\": os.getenv(\"IdAnd_Ozon\"),\n",
    "        \"api_key\": os.getenv(\"KeyAnd_Ozon\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ozon-Braun Russia-19885\",\n",
    "        \"client_id\": os.getenv(\"IdBraun_Ozon\"),\n",
    "        \"api_key\": os.getenv(\"KeyBraun_Ozon\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ozon-CASO-100304\",\n",
    "        \"client_id\": os.getenv(\"IdCaso_Ozon\"),\n",
    "        \"api_key\": os.getenv(\"KeyCaso_Ozon\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ozon-Gillette-Club-80466\",\n",
    "        \"client_id\": os.getenv(\"IdGillette_Ozon\"),\n",
    "        \"api_key\": os.getenv(\"KeyGillette_Ozon\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ozon-GUTENTECH-1547\",\n",
    "        \"client_id\": os.getenv(\"IdGuten_Ozon\"),\n",
    "        \"api_key\": os.getenv(\"KeyGuten_Ozon\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ozon-KitchenAid-1638\",\n",
    "        \"client_id\": os.getenv(\"IdKitchen_Ozon\"),\n",
    "        \"api_key\": os.getenv(\"KeyKitchen_Ozon\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ozon-Smart Market-1676213\",\n",
    "        \"client_id\": os.getenv(\"IdSmart_Ozon\"),\n",
    "        \"api_key\": os.getenv(\"KeySmart_Ozon\")\n",
    "    }\n",
    "]\n",
    "\n",
    "# === URL API ===\n",
    "url = \"https://api-seller.ozon.ru/v3/finance/transaction/list\" \n",
    "\n",
    "# === Фильтр по дате: последние 2 дня ===\n",
    "end_date = datetime.today() - timedelta(days=1)\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "# === Сюда будем собирать данные со всех проектов ===\n",
    "all_data = []\n",
    "\n",
    "for project in projects:\n",
    "    print(f\"Получаем данные для проекта: {project['name']}\")\n",
    "\n",
    "    client_id = project[\"client_id\"]\n",
    "    api_key = project[\"api_key\"]\n",
    "\n",
    "    if not client_id or not api_key:\n",
    "        print(f\"Не указаны Client-ID или API-Key для проекта: {project['name']}\")\n",
    "        continue\n",
    "\n",
    "    headers = {\n",
    "        \"Client-Id\": client_id,\n",
    "        \"Api-Key\": api_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    body = {\n",
    "        \"filter\": {\n",
    "            \"date\": {\n",
    "                \"from\": start_date.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\"),\n",
    "                \"to\": end_date.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "            },\n",
    "            \"operation_type\": [],\n",
    "            \"posting_number\": \"\",\n",
    "            \"transaction_type\": \"all\"\n",
    "        },\n",
    "        \"page\": 1,\n",
    "        \"page_size\": 1000\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(body))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Данные получены для {project['name']}\")\n",
    "        operations = response.json().get(\"result\", {}).get(\"operations\", [])\n",
    "\n",
    "        if not operations:\n",
    "            print(f\"Нет данных за указанный период для {project['name']}\")\n",
    "            continue\n",
    "\n",
    "        # === Подготовка данных ===\n",
    "        rows = []\n",
    "        for op in operations:\n",
    "            base = {\n",
    "                'operation_id': op.get('operation_id'),\n",
    "                'operation_type': op.get('operation_type'),\n",
    "                'operation_date': op.get('operation_date'),\n",
    "                'operation_type_name': op.get('operation_type_name'),\n",
    "                'delivery_charge': op.get('delivery_charge'),\n",
    "                'return_delivery_charge': op.get('return_delivery_charge'),\n",
    "                'accruals_for_sale': op.get('accruals_for_sale'),\n",
    "                'sale_commission': op.get('sale_commission'),\n",
    "                'amount': op.get('amount'),\n",
    "                'type': op.get('type')\n",
    "            }\n",
    "\n",
    "            posting = op.get('posting', {})\n",
    "            base.update({\n",
    "                'posting_delivery_schema': posting.get('delivery_schema'),\n",
    "                'posting_order_date': posting.get('order_date'),\n",
    "                'posting_posting_number': posting.get('posting_number'),\n",
    "                'posting_warehouse_id': posting.get('warehouse_id')\n",
    "            })\n",
    "\n",
    "            items = op.get('items', [])\n",
    "            if items:\n",
    "                item = items[0]\n",
    "                base.update({\n",
    "                    'item_name': item.get('name'),\n",
    "                    'item_sku': item.get('sku')\n",
    "                })\n",
    "            else:\n",
    "                base.update({'item_name': None, 'item_sku': None})\n",
    "\n",
    "            services = op.get('services', [])\n",
    "            if services:\n",
    "                service = services[0]\n",
    "                base.update({\n",
    "                    'service_name': service.get('name'),\n",
    "                    'service_price': service.get('price')\n",
    "                })\n",
    "            else:\n",
    "                base.update({'service_name': None, 'service_price': None})\n",
    "\n",
    "            # Добавляем имя проекта\n",
    "            base['project'] = project['name']\n",
    "\n",
    "            rows.append(base)\n",
    "\n",
    "        all_data.extend(rows)\n",
    "\n",
    "    else:\n",
    "        print(f\"Ошибка при запросе к Ozon API для {project['name']}: {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "# === Создание общего DataFrame ===\n",
    "if all_data:\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # === Явное приведение типов под схему ClickHouse ===\n",
    "    df['operation_id'] = pd.to_numeric(df['operation_id'], errors='coerce').fillna(0).astype('int64')\n",
    "    df['delivery_charge'] = pd.to_numeric(df['delivery_charge'], errors='coerce').fillna(0).astype('float64')\n",
    "    df['return_delivery_charge'] = pd.to_numeric(df['return_delivery_charge'], errors='coerce').fillna(0).astype('float64')\n",
    "    df['accruals_for_sale'] = pd.to_numeric(df['accruals_for_sale'], errors='coerce').fillna(0).astype('float64')\n",
    "    df['sale_commission'] = pd.to_numeric(df['sale_commission'], errors='coerce').fillna(0).astype('float64')\n",
    "    df['amount'] = pd.to_numeric(df['amount'], errors='coerce').fillna(0).astype('float64')\n",
    "    df['item_sku'] = pd.to_numeric(df['item_sku'], errors='coerce').fillna(0).astype('int64')\n",
    "\n",
    "    # === Преобразование дат в datetime и замена NaT на None ===\n",
    "    df['operation_date'] = pd.to_datetime(df['operation_date'], errors='coerce')\n",
    "    df['posting_order_date'] = pd.to_datetime(df['posting_order_date'], errors='coerce')\n",
    "\n",
    "    # Замена NaT на None для Nullable(DateTime) полей\n",
    "    df['operation_date'] = df['operation_date'].where(df['operation_date'].notnull(), None)\n",
    "    df['posting_order_date'] = df['posting_order_date'].where(df['posting_order_date'].notnull(), None)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Нет данных для отображения\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8d077fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5500 entries, 0 to 5499\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   operation_id             5500 non-null   int64         \n",
      " 1   operation_type           5500 non-null   object        \n",
      " 2   operation_date           5500 non-null   datetime64[ns]\n",
      " 3   operation_type_name      5500 non-null   object        \n",
      " 4   delivery_charge          5500 non-null   float64       \n",
      " 5   return_delivery_charge   5500 non-null   float64       \n",
      " 6   accruals_for_sale        5500 non-null   float64       \n",
      " 7   sale_commission          5500 non-null   float64       \n",
      " 8   amount                   5500 non-null   float64       \n",
      " 9   type                     5500 non-null   object        \n",
      " 10  posting_delivery_schema  5500 non-null   object        \n",
      " 11  posting_order_date       5250 non-null   datetime64[ns]\n",
      " 12  posting_posting_number   5500 non-null   object        \n",
      " 13  posting_warehouse_id     5500 non-null   int64         \n",
      " 14  item_name                4448 non-null   object        \n",
      " 15  item_sku                 5500 non-null   int64         \n",
      " 16  service_name             4400 non-null   object        \n",
      " 17  service_price            4400 non-null   float64       \n",
      " 18  project                  5500 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(6), int64(3), object(8)\n",
      "memory usage: 816.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76d1a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "password = os.getenv('ClickHouse')\n",
    "# Define connection parameters\n",
    "client = get_client(\n",
    "    host='rc1a-j5ou9lq30ldal602.mdb.yandexcloud.net',  # Your Yandex Cloud ClickHouse host\n",
    "    port=8443,                                          # Yandex Cloud uses port 8443 for HTTPS\n",
    "    username='user1',                           # Your ClickHouse username\n",
    "    password= password,                           # Your ClickHouse password\n",
    "    database='user1',                            # Your database name\n",
    "    secure=True,                                        # Use HTTPS\n",
    "    verify=False                                        # Disable SSL certificate verification \n",
    "    # Define the data to insert\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bcc80c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error serializing column `posting_order_date` into data type `Nullable(DateTime)`\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\driver\\transform.py\", line 99, in chunk_gen\n",
      "    col_type.write_column(data, output, context)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\datatypes\\base.py\", line 214, in write_column\n",
      "    self.write_column_data(column, dest, ctx)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\datatypes\\base.py\", line 229, in write_column_data\n",
      "    self._write_column_binary(column, dest, ctx)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\datatypes\\temporal.py\", line 132, in _write_column_binary\n",
      "    column = [int(x.timestamp()) if x else 0 for x in column]\n",
      "                  ~~~~~~~~~~~^^\n",
      "  File \"nattype.pyx\", line 54, in pandas._libs.tslibs.nattype._make_error_func.f\n",
      "ValueError: NaTType does not support timestamp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data to insert: [('Ozon-A&D Rus-1112223', 32479221362, 'OperationAgentDeliveredToCustomer', Timestamp('2025-05-10 00:00:00'), 'Доставка покупателю', 0.0, 0.0, 4811.0, -962.2, 3379.88, 'orders', 'FBO', Timestamp('2025-05-07 22:50:18'), '86937412-0035-1', 1020000890160000, 'Массажер антицеллюлитный медицинский электрический Nozomi MH-102 с лампой инфракрасного излучения, массаж для шеи и плеч, суставов и тела', 959010529, 'MarketplaceServiceItemDelivToCustomer', -215.04), ('Ozon-A&D Rus-1112223', 32479283941, 'MarketplaceRedistributionOfAcquiringOperation', Timestamp('2025-05-10 00:00:00'), 'Оплата эквайринга', 0.0, 0.0, 0.0, 0.0, -10.79, 'other', '', Timestamp('2025-05-10 05:20:57'), '50116110-0084', 0, 'Груша (нагнетатель) AND RB-101G', 1056477332, 'MarketplaceRedistributionOfAcquiringOperation', -10.79), ('Ozon-A&D Rus-1112223', 32479976826, 'MarketplaceRedistributionOfAcquiringOperation', Timestamp('2025-05-10 00:00:00'), 'Оплата эквайринга', 0.0, 0.0, 0.0, 0.0, -38.36, 'other', '', Timestamp('2025-05-07 15:33:45'), '59817565-0111', 0, 'Тонометр автоматический, на батарейках, манжета 22-32 см, AND UA-888 E ЭКОНОМ, на плечо', 958575783, 'MarketplaceRedistributionOfAcquiringOperation', -38.36), ('Ozon-A&D Rus-1112223', 32480444908, 'MarketplaceRedistributionOfAcquiringOperation', Timestamp('2025-05-10 00:00:00'), 'Оплата эквайринга', 0.0, 0.0, 0.0, 0.0, -31.09, 'other', '', Timestamp('2025-05-10 07:26:43'), '0127295226-0042', 0, 'Массажер антицеллюлитный медицинский электрический Nozomi MH-102 с лампой инфракрасного излучения, массаж для шеи и плеч, суставов и тела', 959010529, 'MarketplaceRedistributionOfAcquiringOperation', -31.09), ('Ozon-A&D Rus-1112223', 32482465387, 'OperationAgentDeliveredToCustomer', Timestamp('2025-05-10 00:00:00'), 'Доставка покупателю', 0.0, 0.0, 574.0, -103.32, 377.61, 'orders', 'FBO', Timestamp('2025-05-06 15:48:59'), '25360286-0269-1', 23843917228000, 'Термометр экономичный цифровой электронный AND DT-501 / звуковой сигнал / с футляром', 956912307, 'MarketplaceServiceItemDelivToCustomer', -24.26)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NaTType does not support timestamp",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m table_name = \u001b[33m'\u001b[39m\u001b[33mozon_finance\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Use the insert method for bulk insertion\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData inserted successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\driver\\client.py:635\u001b[39m, in \u001b[36mClient.insert\u001b[39m\u001b[34m(self, table, data, column_names, database, column_types, column_type_names, column_oriented, settings, context)\u001b[39m\n\u001b[32m    633\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ProgrammingError(\u001b[33m'\u001b[39m\u001b[33mAttempting to insert new data with non-empty insert context\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    634\u001b[39m     context.data = data\n\u001b[32m--> \u001b[39m\u001b[32m635\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:280\u001b[39m, in \u001b[36mHttpClient.data_insert\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    277\u001b[39m     params[\u001b[33m'\u001b[39m\u001b[33mdatabase\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.database\n\u001b[32m    278\u001b[39m params.update(\u001b[38;5;28mself\u001b[39m._validate_settings(context.settings))\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_wait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m logger.debug(\u001b[33m'\u001b[39m\u001b[33mContext insert response code: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m, content: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m, response.status, response.data)\n\u001b[32m    282\u001b[39m context.data = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:472\u001b[39m, in \u001b[36mHttpClient._raw_request\u001b[39m\u001b[34m(self, data, params, headers, method, retries, stream, server_wait, fields, error_handler)\u001b[39m\n\u001b[32m    470\u001b[39m     logger.debug(\u001b[33m'\u001b[39m\u001b[33mRetrying requests with status code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m, response.status)\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_handler:\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[43merror_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    474\u001b[39m     \u001b[38;5;28mself\u001b[39m._error_handler(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:265\u001b[39m, in \u001b[36mHttpClient.data_insert.<locals>.error_handler\u001b[39m\u001b[34m(resp)\u001b[39m\n\u001b[32m    263\u001b[39m     ex = context.insert_exception\n\u001b[32m    264\u001b[39m     context.insert_exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[32m    266\u001b[39m \u001b[38;5;28mself\u001b[39m._error_handler(resp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\driver\\transform.py:99\u001b[39m, in \u001b[36mNativeTransform.build_insert.<locals>.chunk_gen\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     97\u001b[39m context.start_column(col_name)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[43mcol_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# This is hideous, but some low level serializations can fail while streaming\u001b[39;00m\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# the insert if the user has included bad data in the column.  We need to ensure that the\u001b[39;00m\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# insert fails (using garbage data) to avoid a partial insert, and use the context to\u001b[39;00m\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# propagate the correct exception to the user\u001b[39;00m\n\u001b[32m    105\u001b[39m     logger.error(\u001b[33m'\u001b[39m\u001b[33mError serializing column `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m` into data type `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    106\u001b[39m                  col_name, col_type.name, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\datatypes\\base.py:214\u001b[39m, in \u001b[36mClickHouseType.write_column\u001b[39m\u001b[34m(self, column, dest, ctx)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03mWrapping write method for ClickHouseTypes.  Only overridden for container types that so that\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03mthe write_native_prefix is done at the right time for contained types\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    211\u001b[39m \u001b[33;03m:param ctx: Insert Context with insert specific settings\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28mself\u001b[39m.write_column_prefix(dest)\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_column_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\datatypes\\base.py:229\u001b[39m, in \u001b[36mClickHouseType.write_column_data\u001b[39m\u001b[34m(self, column, dest, ctx)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nullable:\n\u001b[32m    228\u001b[39m     dest += \u001b[38;5;28mbytes\u001b[39m([\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m column])\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_column_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data\\.venv\\Lib\\site-packages\\clickhouse_connect\\datatypes\\temporal.py:132\u001b[39m, in \u001b[36mDateTime._write_column_binary\u001b[39m\u001b[34m(self, column, dest, ctx)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nullable:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m         column = [\u001b[38;5;28mint\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m column]\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    134\u001b[39m         column = [\u001b[38;5;28mint\u001b[39m(x.timestamp()) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m column]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnattype.pyx:54\u001b[39m, in \u001b[36mpandas._libs.tslibs.nattype._make_error_func.f\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: NaTType does not support timestamp"
     ]
    }
   ],
   "source": [
    "# Ensure the DataFrame has the correct columns\n",
    "columns = ['project','operation_id', 'operation_type', 'operation_date',\n",
    "       'operation_type_name', 'delivery_charge', 'return_delivery_charge',\n",
    "       'accruals_for_sale', 'sale_commission', 'amount', 'type',\n",
    "       'posting_delivery_schema', 'posting_order_date',\n",
    "       'posting_posting_number', 'posting_warehouse_id', 'item_name',\n",
    "       'item_sku', 'service_name', 'service_price']\n",
    "\n",
    "# Reorder columns to match the expected order\n",
    "df_modified = df[columns]\n",
    "# Convert DataFrame to a list of tuples for bulk insertion\n",
    "data = [tuple(row) for row in df_modified.to_numpy()]\n",
    "\n",
    "# Debugging: Check the structure of the data\n",
    "print(\"Sample data to insert:\", data[:5])  # Print the first 5 rows to check the structure\n",
    "\n",
    "# Define the table name\n",
    "table_name = 'ozon_finance'\n",
    "# Use the insert method for bulk insertion\n",
    "client.insert(table_name, data, column_names=columns)\n",
    "print(\"Data inserted successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
